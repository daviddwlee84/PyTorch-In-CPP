
```
(research) ➜  5_Try_Pure_Cpp_Model git:(main) ✗ ./build/benchmark 10000 1
Default Torch Threads: 60
Updated Torch Threads: 1
Will use average of 10000 iterations.
Benchmarking Pure LibTorch C++ model...
0.01 *
 5.2228
[ CPUFloatType{1,1} ]
Inference time: 0.000842156 seconds
```

=> Basic the same as load model using Python dumped TorchScript

- https://chatgpt.com/share/032ef67d-7e6c-4d54-b1eb-d2115fedf9b4
